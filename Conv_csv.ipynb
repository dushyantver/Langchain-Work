{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import all the Required Liberaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders.csv_loader import CSVLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.llms import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Load the Dataset --> CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_FAISS_PATH = \"vectorstore/db_faiss\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content='City: New York City\\nCountry: \"United States of America\"\\nAirQuality: 46.81603774\\nWaterPollution: 49.5049505', metadata={'source': 'D:\\\\Data_analytics_new\\\\Generative_AI\\\\Langchain\\\\Langchain-Work\\\\air_water_data.csv', 'row': 0}), Document(page_content='City: Washington, D.C.\\nCountry: \"United States of America\"\\nAirQuality: 66.12903226\\nWaterPollution: 49.10714286', metadata={'source': 'D:\\\\Data_analytics_new\\\\Generative_AI\\\\Langchain\\\\Langchain-Work\\\\air_water_data.csv', 'row': 1}), Document(page_content='City: San Francisco\\nCountry: \"United States of America\"\\nAirQuality: 60.51401869\\nWaterPollution: 43', metadata={'source': 'D:\\\\Data_analytics_new\\\\Generative_AI\\\\Langchain\\\\Langchain-Work\\\\air_water_data.csv', 'row': 2}), Document(page_content='City: Berlin\\nCountry: \"Germany\"\\nAirQuality: 62.36413043\\nWaterPollution: 28.61271676', metadata={'source': 'D:\\\\Data_analytics_new\\\\Generative_AI\\\\Langchain\\\\Langchain-Work\\\\air_water_data.csv', 'row': 3}), Document(page_content='City: Los Angeles\\nCountry: \"United States of America\"\\nAirQuality: 36.62162162\\nWaterPollution: 61.29943503', metadata={'source': 'D:\\\\Data_analytics_new\\\\Generative_AI\\\\Langchain\\\\Langchain-Work\\\\air_water_data.csv', 'row': 4}), Document(page_content='City: Bern\\nCountry: \"Switzerland\"\\nAirQuality: 94.31818182\\nWaterPollution: 12.5', metadata={'source': 'D:\\\\Data_analytics_new\\\\Generative_AI\\\\Langchain\\\\Langchain-Work\\\\air_water_data.csv', 'row': 5}), Document(page_content='City: Geneva\\nCountry: \"Switzerland\"\\nAirQuality: 71.53846154\\nWaterPollution: 17.37288136', metadata={'source': 'D:\\\\Data_analytics_new\\\\Generative_AI\\\\Langchain\\\\Langchain-Work\\\\air_water_data.csv', 'row': 6}), Document(page_content='City: Zurich\\nCountry: \"Switzerland\"\\nAirQuality: 83.80952381\\nWaterPollution: 10.71428571', metadata={'source': 'D:\\\\Data_analytics_new\\\\Generative_AI\\\\Langchain\\\\Langchain-Work\\\\air_water_data.csv', 'row': 7}), Document(page_content='City: Basel\\nCountry: \"Switzerland\"\\nAirQuality: 81.66666667\\nWaterPollution: 26.92307692', metadata={'source': 'D:\\\\Data_analytics_new\\\\Generative_AI\\\\Langchain\\\\Langchain-Work\\\\air_water_data.csv', 'row': 8}), Document(page_content='City: London\\nCountry: \"United Kingdom\"\\nAirQuality: 37.04225352\\nWaterPollution: 40.71637427', metadata={'source': 'D:\\\\Data_analytics_new\\\\Generative_AI\\\\Langchain\\\\Langchain-Work\\\\air_water_data.csv', 'row': 9}), Document(page_content='City: Cairo\\nCountry: \"Egypt\"\\nAirQuality: 15.830721\\nWaterPollution: 74.35064935', metadata={'source': 'D:\\\\Data_analytics_new\\\\Generative_AI\\\\Langchain\\\\Langchain-Work\\\\air_water_data.csv', 'row': 10}), Document(page_content='City: Alexandria\\nCountry: \"Egypt\"\\nAirQuality: 41.03773585\\nWaterPollution: 71.2962963', metadata={'source': 'D:\\\\Data_analytics_new\\\\Generative_AI\\\\Langchain\\\\Langchain-Work\\\\air_water_data.csv', 'row': 11}), Document(page_content='City: Alexandria\\nCountry: \"United States of America\"\\nAirQuality: 89.0625\\nWaterPollution: 46.15384615', metadata={'source': 'D:\\\\Data_analytics_new\\\\Generative_AI\\\\Langchain\\\\Langchain-Work\\\\air_water_data.csv', 'row': 12}), Document(page_content='City: Paris\\nCountry: \"France\"\\nAirQuality: 34.02439024\\nWaterPollution: 43.12169312', metadata={'source': 'D:\\\\Data_analytics_new\\\\Generative_AI\\\\Langchain\\\\Langchain-Work\\\\air_water_data.csv', 'row': 13})]\n"
     ]
    }
   ],
   "source": [
    "loader = CSVLoader(file_path=\"D:\\\\Data_analytics_new\\\\Generative_AI\\\\Langchain\\\\Langchain-Work\\\\air_water_data.csv\", encoding=\"utf-8\", csv_args={'delimiter': ','})\n",
    "data = loader.load()\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Split the Text into Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the text into Chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=100, chunk_overlap=20)\n",
    "text_chunks = text_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    }
   ],
   "source": [
    "print(len(text_chunks))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Embedding := Use the Sentence Transformer Embedding from Hugging Face Liberary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Sentence Transformers Embedding From Hugging Face\n",
    "embeddings = HuggingFaceEmbeddings(model_name = 'sentence-transformers/all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "#embeddings_model = OpenAIEmbeddings(openai_api_key=os.getenv(\"OpenAI_API_Key\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. FAISS Vector Space is Used to Store the Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COnverting the text Chunks into embeddings and saving the embeddings into FAISS Knowledge Base\n",
    "docsearch = FAISS.from_documents(text_chunks, embeddings)\n",
    "\n",
    "docsearch.save_local(DB_FAISS_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. OpenAI LLM Model Gpt is Used for Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "openai_api_key = os.getenv(\"OpenAI_API_Key\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
    "llm = OpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from langchain.agents import AgentType, initialize_agent, load_tools\n",
    "#from langchain import LLMMathChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from langchain.llms import CTransformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#llm = CTransformers(model=\"D:\\\\Data_analytics_new\\\\Generative_AI\\\\Langchain\\\\Langchain-Work\\\\model\\\\llama-2-7b-chat.ggmlv3.q4_0.bin\",\n",
    " #                   model_type=\"llama\",\n",
    "  #                  max_new_tokens=512,\n",
    "   #                 temperature=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LLM_Math_chain = LLMMathChain.from_llm(llm=llm, verbose=True)\n",
    "#math_tool = Tool.from_function(func = LLM_Math_chain.run)\n",
    "#tools = load_tools([\"llm-math\"],llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#agent.run(\"columns name in dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = ConversationalRetrievalChain.from_llm(llm, retriever=docsearch.as_retriever())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response:   The airquality of New York City is 46.81603774.\n",
      "Exiting\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Oliver\\anaconda4\\envs\\llms\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3516: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    chat_history = []\n",
    "    query = input(f\"Input Prompt: \")\n",
    "    if query == 'exit':\n",
    "        print('Exiting')\n",
    "        sys.exit()\n",
    "    if query == '':\n",
    "        continue\n",
    "    result = chain({\"question\":query, \"chat_history\":chat_history})\n",
    "    print(\"Response: \", result['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 4\n"
     ]
    }
   ],
   "source": [
    "#chat_history = []\n",
    "#query = \"How many rows are there in the dataset\"\n",
    "#response = chain({\"question\": query,\"chat_history\":chat_history})\n",
    "#print(response['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
